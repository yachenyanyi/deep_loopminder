#!/usr/bin/env python3
"""
åˆ›å»º30ä¸ªæ¨¡æ‹Ÿçš„MCPå·¥å…·æ•°æ®ï¼Œç”¨äºæµ‹è¯•å…³é”®è¯åŒ¹é…åŠŸèƒ½
"""
from langchain_core.tools import StructuredTool
from pydantic import BaseModel, Field
import os
import mimetypes
import asyncio
import base64
import json
import re
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_mcp_adapters.tools import load_mcp_tools
import atexit
from typing import List, Dict, Any
from difflib import SequenceMatcher
MOCK_TOOLS = [
    {
        "name": "SearchDocsByLangChain",
        "description": "Search across the Docs by LangChain knowledge base to find relevant information, code examples, API references, and guides. Use this tool when you need to answer questions about Docs by LangChain, find specific documentation, understand how features work, or locate implementation details. The search returns contextual content with titles and direct links to the documentation pages."
    },
    {
        "name": "fetch",
        "description": "Fetch content from a URL and optionally extract it as markdown. This tool can be used to retrieve web pages, API responses, or any HTTP-accessible content. It supports various content types and can convert HTML to markdown for easier processing."
    },
    {
        "name": "CodeAnalyzer",
        "description": "Analyze source code for quality, security issues, and best practices. Supports multiple programming languages including Python, JavaScript, TypeScript, Java, and Go. Provides detailed reports on code complexity, potential bugs, and style violations."
    },
    {
        "name": "DatabaseQuery",
        "description": "Execute SQL queries against connected databases. Supports PostgreSQL, MySQL, SQLite, and MongoDB. Provides secure parameterized queries, result formatting, and connection pooling for efficient database operations."
    },
    {
        "name": "FileSystemManager",
        "description": "Manage file system operations including reading, writing, copying, moving, and deleting files and directories. Provides cross-platform compatibility and secure file handling with proper permission management."
    },
    {
        "name": "APIConnector",
        "description": "Connect to REST APIs with automatic authentication, rate limiting, and retry mechanisms. Supports OAuth 2.0, API keys, and custom authentication methods. Handles JSON/XML parsing and error handling."
    },
    {
        "name": "TextProcessor",
        "description": "Process and transform text data with advanced features including regex matching, string replacement, case conversion, encoding detection, and text extraction. Supports Unicode and multiple character encodings."
    },
    {
        "name": "ImageProcessor",
        "description": "Process images with operations like resize, crop, rotate, format conversion, and filter application. Supports JPEG, PNG, GIF, WebP formats. Provides batch processing and optimization features."
    },
    {
        "name": "PDFExtractor",
        "description": "Extract text, images, and metadata from PDF files. Supports encrypted PDFs, table extraction, and form data processing. Can convert PDFs to other formats like HTML or plain text."
    },
    {
        "name": "EmailSender",
        "description": "Send emails with HTML/text content, attachments, and template support. Integrates with SMTP servers, handles authentication, and provides delivery status tracking. Supports bulk email operations."
    },
    {
        "name": "WebScraper",
        "description": "Extract data from web pages using CSS selectors, XPath, or regular expressions. Handles JavaScript-rendered content, pagination, and anti-bot measures. Provides data cleaning and export features."
    },
    {
        "name": "DataValidator",
        "description": "Validate data against schemas, business rules, and custom constraints. Supports JSON Schema, XML Schema, and custom validation functions. Provides detailed error messages and validation reports."
    },
    {
        "name": "CacheManager",
        "description": "Manage caching operations with support for Redis, Memcached, and in-memory caching. Provides TTL management, cache invalidation, and performance metrics. Supports distributed caching scenarios."
    },
    {
        "name": "Logger",
        "description": "Advanced logging system with multiple handlers, formatters, and filters. Supports structured logging, log rotation, and remote log aggregation. Integrates with popular monitoring systems."
    },
    {
        "name": "ConfigManager",
        "description": "Manage application configuration from files, environment variables, and remote sources. Supports hot-reloading, configuration validation, and environment-specific settings. Provides secure secret management."
    },
    {
        "name": "SecurityScanner",
        "description": "Scan code and dependencies for security vulnerabilities. Checks against CVE databases, performs static analysis, and identifies potential security risks. Provides remediation recommendations."
    },
    {
        "name": "PerformanceProfiler",
        "description": "Profile application performance with CPU, memory, and I/O analysis. Identifies bottlenecks, memory leaks, and optimization opportunities. Provides visual reports and performance metrics."
    },
    {
        "name": "MachineLearning",
        "description": "Train and deploy machine learning models with support for classification, regression, and clustering. Integrates with scikit-learn, TensorFlow, and PyTorch. Provides model evaluation and hyperparameter tuning."
    },
    {
        "name": "DataVisualization",
        "description": "Create charts, graphs, and interactive visualizations from data. Supports matplotlib, Plotly, and D3.js. Provides statistical analysis features and export to multiple formats."
    },
    {
        "name": "DocumentGenerator",
        "description": "Generate documents in various formats including PDF, Word, HTML, and Markdown. Supports templates, dynamic content insertion, and styling. Provides mail merge and batch generation capabilities."
    },
    {
        "name": "BackupManager",
        "description": "Automated backup and restore operations for files, databases, and system configurations. Supports incremental backups, compression, encryption, and cloud storage integration."
    },
    {
        "name": "NotificationService",
        "description": "Send notifications through multiple channels including email, SMS, Slack, and webhooks. Supports templating, scheduling, and delivery tracking. Integrates with popular messaging platforms."
    },
    {
        "name": "WorkflowEngine",
        "description": "Orchestrate complex workflows with conditional logic, parallel execution, and error handling. Supports task dependencies, retry mechanisms, and progress tracking. Provides visual workflow designer."
    },
    {
        "name": "APIRateLimiter",
        "description": "Implement rate limiting for API endpoints with configurable limits and time windows. Supports burst handling, client identification, and distributed rate limiting. Provides usage analytics."
    },
    {
        "name": "DataTransformer",
        "description": "Transform data between different formats including JSON, XML, CSV, and Parquet. Supports schema mapping, data validation, and batch processing. Provides streaming transformation capabilities."
    },
    {
        "name": "SearchEngine",
        "description": "Full-text search functionality with indexing, querying, and ranking. Supports Elasticsearch, Solr, and SQLite FTS. Provides fuzzy matching, faceted search, and search result highlighting."
    },
    {
        "name": "CryptoManager",
        "description": "Handle cryptographic operations including encryption, decryption, hashing, and digital signatures. Supports multiple algorithms and key management. Provides secure random number generation."
    },
    {
        "name": "NetworkAnalyzer",
        "description": "Analyze network traffic, monitor connectivity, and diagnose network issues. Supports packet capture, port scanning, and bandwidth monitoring. Provides network topology mapping."
    },
    {
        "name": "TimeSeries",
        "description": "Process and analyze time series data with trend analysis, seasonality detection, and anomaly identification. Supports forecasting, aggregation, and data interpolation. Integrates with pandas and NumPy."
    },
    {
        "name": "GraphDatabase",
        "description": "Interact with graph databases to store and query connected data. Supports Neo4j, ArangoDB, and network analysis algorithms. Provides path finding, centrality analysis, and graph visualization."
    }
]
def _filter_tools_by_query(
    tool_dicts: List[Dict[str, Any]], 
    query: str = "",
    match_threshold: float = 0.3,
    max_results: int = 50
) -> List[Dict[str, Any]]:
    """
    äººæ€§åŒ–çš„å·¥å…·ç­›é€‰å‡½æ•°ï¼Œæ”¯æŒå¤šç§åŒ¹é…ç­–ç•¥
    
    Args:
        tool_dicts: å·¥å…·å­—å…¸åˆ—è¡¨
        query: æŸ¥è¯¢å…³é”®è¯
        match_threshold: æ¨¡ç³ŠåŒ¹é…é˜ˆå€¼ (0-1)
        max_results: æœ€å¤§è¿”å›ç»“æœæ•°
    
    Returns:
        è¿‡æ»¤åçš„å·¥å…·å­—å…¸åˆ—è¡¨ï¼ŒæŒ‰åŒ¹é…åº¦æ’åº
    """
    if not query or not tool_dicts:
        return tool_dicts[:max_results]
    
    # é¢„å¤„ç†æŸ¥è¯¢è¯
    q = query.lower().strip()
    q_words = re.findall(r'\b\w+\b', q)  # åˆ†å‰²å•è¯
    q_words = [w for w in q_words if len(w) > 1]  # è¿‡æ»¤æ‰å•ä¸ªå­—æ¯
    
    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå•è¯ï¼Œè¿”å›ç©º
    if not q_words:
        return []
    
    scored_tools = []
    
    for tool in tool_dicts:
        name = tool.get("name", "").lower()
        description = tool.get("description", "").lower()
        
        # åˆå§‹åŒ–åŒ¹é…åˆ†æ•°
        score = 0
        matched_fields = []
        
        # 1. ç²¾ç¡®åŒ¹é… (æœ€é«˜ä¼˜å…ˆçº§)
        if q == name:
            score += 100  # åç§°å®Œå…¨åŒ¹é…
            matched_fields.append("åç§°å®Œå…¨åŒ¹é…")
        elif q in name:
            score += 50  # åç§°åŒ…å«å®Œæ•´æŸ¥è¯¢è¯
            matched_fields.append("åç§°åŒ…å«æŸ¥è¯¢è¯")
        elif q in description:
            score += 30  # æè¿°åŒ…å«å®Œæ•´æŸ¥è¯¢è¯
            matched_fields.append("æè¿°åŒ…å«æŸ¥è¯¢è¯")
        
        # 2. å•è¯åŒ¹é…
        name_words = re.findall(r'\b\w+\b', name)
        desc_words = re.findall(r'\b\w+\b', description)
        
        # åç§°ä¸­çš„å•è¯åŒ¹é…
        name_word_matches = 0
        for q_word in q_words:
            for n_word in name_words:
                if q_word in n_word or n_word in q_word:
                    score += 10
                    name_word_matches += 1
                    break
        
        # æè¿°ä¸­çš„å•è¯åŒ¹é…
        desc_word_matches = 0
        for q_word in q_words:
            for d_word in desc_words:
                if q_word in d_word or d_word in q_word:
                    score += 5
                    desc_word_matches += 1
                    break
        
        if name_word_matches > 0:
            matched_fields.append(f"åç§°åŒ¹é…{name_word_matches}ä¸ªå•è¯")
        if desc_word_matches > 0:
            matched_fields.append(f"æè¿°åŒ¹é…{desc_word_matches}ä¸ªå•è¯")
        
        # 3. æ¨¡ç³ŠåŒ¹é… (ç”¨äºå¤„ç†æ‹¼å†™é”™è¯¯æˆ–ç›¸ä¼¼è¯)
        best_fuzzy_score = 0
        for q_word in q_words:
            # ä¸åç§°ä¸­çš„å•è¯æ¨¡ç³ŠåŒ¹é…
            for n_word in name_words:
                ratio = SequenceMatcher(None, q_word, n_word).ratio()
                if ratio > match_threshold and ratio > best_fuzzy_score:
                    best_fuzzy_score = ratio
                    score += int(ratio * 20)  # æ ¹æ®ç›¸ä¼¼åº¦ç»™åˆ†
            
            # ä¸æè¿°ä¸­çš„å•è¯æ¨¡ç³ŠåŒ¹é…
            for d_word in desc_words:
                ratio = SequenceMatcher(None, q_word, d_word).ratio()
                if ratio > match_threshold and ratio > best_fuzzy_score:
                    best_fuzzy_score = ratio
                    score += int(ratio * 10)  # æè¿°æ¨¡ç³ŠåŒ¹é…æƒé‡è¾ƒä½
        
        if best_fuzzy_score > 0:
            matched_fields.append(f"æ¨¡ç³ŠåŒ¹é…({best_fuzzy_score:.2f})")
        
        # 4. é¦–å­—æ¯åŒ¹é… (ç¼©å†™åŒ¹é…)
        if len(q_words) == 1 and len(q_words[0]) <= 4:
            # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·åçš„é¦–å­—æ¯ç¼©å†™
            if len(name_words) >= len(q_words[0]):
                initials = ''.join([w[0] for w in name_words if w])
                if q_words[0] in initials:
                    score += 15
                    matched_fields.append("é¦–å­—æ¯ç¼©å†™åŒ¹é…")
        
        # 5. åˆ†ç±»/æ ‡ç­¾åŒ¹é… (å¦‚æœå·¥å…·æœ‰åˆ†ç±»ä¿¡æ¯)
        categories = tool.get("categories", [])
        if categories:
            for category in categories:
                cat_lower = category.lower()
                if q in cat_lower:
                    score += 25
                    matched_fields.append(f"åˆ†ç±»åŒ¹é…: {category}")
                else:
                    # æ£€æŸ¥æ˜¯å¦åŒ¹é…åˆ†ç±»ä¸­çš„å•è¯
                    for q_word in q_words:
                        if q_word in cat_lower:
                            score += 15
                            matched_fields.append(f"åˆ†ç±»å•è¯åŒ¹é…: {category}")
                            break
        
        # 6. ç›¸å…³æ€§æƒé‡è°ƒæ•´
        # - è¾ƒé•¿çš„æè¿°é€šå¸¸åŒ…å«æ›´å¤šå…³é”®è¯ï¼Œé€‚å½“é™ä½æƒé‡
        if len(description) > 200:
            score *= 0.9
        
        # - å¸¸ç”¨å·¥å…·åŠ åˆ† (å¯ä»¥é€šè¿‡å¤–éƒ¨æ•°æ®æˆ–ä½¿ç”¨é¢‘ç‡æ¥å®šä¹‰)
        common_tools = ["search", "query", "fetch", "get", "find", "list"]
        if any(common in name for common in common_tools):
            score += 5
        
        # åªæœ‰åŒ¹é…çš„å·¥å…·æ‰åŠ å…¥ç»“æœ
        if score > 0:
            scored_tools.append({
                "tool": tool,
                "score": score,
                "matched_fields": matched_fields
            })
    
    # æŒ‰åˆ†æ•°é™åºæ’åº
    scored_tools.sort(key=lambda x: x["score"], reverse=True)
    
    # è¿”å›åŸå§‹å·¥å…·ä¿¡æ¯ï¼Œé™åˆ¶ç»“æœæ•°é‡
    result = [item["tool"] for item in scored_tools[:max_results]]
    
    # å¦‚æœç»“æœå¤ªå¤šï¼Œæ·»åŠ æ™ºèƒ½åˆ†ç»„

    return result
def create_mock_tool_response(query="", page=1, page_size=10):
    """
    æ¨¡æ‹Ÿ list_resources å‡½æ•°çš„è¿”å›æ ¼å¼
    """
    from typing import List, Dict, Any
    
    def filter_tools_by_query(tool_dicts: List[Dict[str, Any]], query: str = "") -> List[Dict[str, Any]]:
        """æ ¹æ®æŸ¥è¯¢å…³é”®è¯è¿‡æ»¤å·¥å…·åˆ—è¡¨"""
        if not query:
            return tool_dicts
        
        q = query.lower().strip()
        if not q:
            return tool_dicts
        
        filtered = [
            tool for tool in tool_dicts
            if q in tool.get("name", "").lower() or q in tool.get("description", "").lower()
        ]
        
        return filtered
    
    # è¿‡æ»¤å·¥å…·
    filtered = filter_tools_by_query(MOCK_TOOLS, query)
    
    # åˆ†é¡µå¤„ç†
    total = len(filtered)
    start = (page - 1) * page_size
    end = start + page_size
    page_items = filtered[start:end]
    
    return {
        "total": total,
        "page": page,
        "page_size": page_size,
        "total_pages": (total + page_size - 1) // page_size,
        "results": page_items,
        "has_next": end < total,
        "has_prev": start > 0
    }

if __name__ == "__main__":
    # æµ‹è¯•ä¸åŒçš„æŸ¥è¯¢
    test_queries = [
        "",
        "search", 
        "fetch",
        "langchain",
        "code",
        "database",
        "image",
        "pdf",
        "email",
        "web",
        "data",
        "cache",
        "log",
        "config",
        "security",
        "performance",
        "machine",
        "visualization",
        "document",
        "backup",
        "notification",
        "workflow",
        "api",
        "transform",
        "crypto",
        "network",
        "time",
        "graph"
    ]
    
    #print("ğŸ§ª æµ‹è¯•å·¥å…·è¿‡æ»¤åŠŸèƒ½")
    #print("=" * 60)
    #
    #for query in test_queries:
    #    result = create_mock_tool_response(query, page=1, page_size=5)
    #    print(f"\næŸ¥è¯¢ '{query}':")
    #    print(f"  æ‰¾åˆ° {result['total']} ä¸ªå·¥å…·")
    #    
    #    if result['results']:
    #        print(f"  å‰å‡ ä¸ªåŒ¹é…çš„å·¥å…·:")
    #        for tool in result['results'][:3]:
    #            print(f"    - {tool['name']}: {tool['description'][:80]}...")
    #
    ## æµ‹è¯•åˆ†é¡µ
    #print("\n" + "=" * 60)
    #print("ğŸ“„ æµ‹è¯•åˆ†é¡µåŠŸèƒ½")
    #print("=" * 60)
    #
    #page1 = create_mock_tool_response("", page=1, page_size=5)
    #page2 = create_mock_tool_response("", page=2, page_size=5)
    #
    #print(f"ç¬¬ä¸€é¡µ: {len(page1['results'])} ä¸ªå·¥å…·")
    #for tool in page1['results']:
    #    print(f"  - {tool['name']}")
    #
    #print(f"\nç¬¬äºŒé¡µ: {len(page2['results'])} ä¸ªå·¥å…·")
    #for tool in page2['results']:
    #    print(f"  - {tool['name']}")
    #
    #print(f"\næ€»å·¥å…·æ•°: {page1['total']}")
    #print(f"æ€»é¡µæ•°: {page1['total_pages']}")
    #print(f"æœ‰ä¸‹ä¸€é¡µ: {page1['has_next']}")
    #print(f"æœ‰ä¸Šä¸€é¡µ: {page1['has_prev']}")ã€

    for i in test_queries:
        result = _filter_tools_by_query(MOCK_TOOLS, query=i,match_threshold=0.1,max_results=5)
        print(f"\næŸ¥è¯¢ '{i}':")
        print(result)
        print(f"----------------------------------------------")